{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf59d0e7",
   "metadata": {},
   "source": [
    "# Model and SGD Backpropagation written only using NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "716e4ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "file_path='mnist.pkl'\n",
    "with open(file_path, 'rb') as f:\n",
    "    x = pickle.load(f, encoding='latin1')\n",
    "\n",
    "y_train=[]\n",
    "x_train=[]\n",
    "y_test=[]\n",
    "x_test=[]\n",
    "##### generating 1000 per class for training ###########\n",
    "ij=np.zeros([10,1])\n",
    "for (ii,i) in enumerate((x[0])[1]):\n",
    "    for j in range(0,10):\n",
    "        if ((i==j) and (int(ij[j,0])<1000)):\n",
    "            x_train.append(((x[0])[0])[ii])\n",
    "            y_train.append(((x[0])[1])[ii])\n",
    "            ij[j,0]+=1\n",
    "\n",
    "##### generating 500 per class for testing ###########            \n",
    "ik=np.zeros([10,1])\n",
    "for (ji,k) in enumerate((x[1])[1]):\n",
    "    for j1 in range(0,10):\n",
    "        if ((k==j1) and (int(ik[j1,0])<500)):\n",
    "            x_test.append(((x[0])[0])[ji])\n",
    "            y_test.append(((x[0])[1])[ji])\n",
    "            ik[j1,0]+=1\n",
    "            \n",
    "x_train, x_test, y_train, y_test = np.asarray(x_train), np.asarray(x_test), np.asarray(y_train), np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11eba1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting Y into one hot vectors\n",
    "Y_train, Y_test = np.zeros((10000,10),dtype='int'), np.zeros((5000,10),dtype='int')\n",
    "for i in range(len(y_train)):\n",
    "    a = y_train[i]\n",
    "    Y_train[i,a] = 1\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    b = y_test[i]\n",
    "    Y_test[i,b] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1408b5f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (10000, 785), x_train_mean: (10000,)\n",
      "1 7.558854837802272\n",
      "2 3.5085378778725484\n",
      "3 3.057031782006857\n",
      "4 2.7643772209949025\n",
      "5 2.588756002212778\n",
      "6 2.4588062131760973\n",
      "7 2.3492253447772744\n",
      "8 2.253262840452515\n",
      "9 2.1680246490526005\n",
      "10 2.091755834138672\n",
      "11 2.0231311474972786\n",
      "12 1.961039941676477\n",
      "13 1.9045615301899086\n",
      "14 1.8529264939681602\n",
      "15 1.8055057363025546\n",
      "16 1.7617702582146058\n",
      "17 1.7212783748365317\n",
      "18 1.6836510289346196\n",
      "19 1.6485661668858849\n",
      "20 1.6157457495233098\n",
      "21 1.5849518942728091\n",
      "22 1.55597891583626\n",
      "23 1.5286496262813971\n",
      "24 1.5028100492006915\n",
      "25 1.4783262810456033\n",
      "26 1.4550810022992793\n",
      "27 1.432971110112604\n",
      "28 1.4119054304094625\n",
      "29 1.3918030267285275\n",
      "30 1.3725916827438152\n",
      "31 1.354206714940555\n",
      "32 1.3365899446458511\n",
      "33 1.3196888628531922\n",
      "34 1.3034559160408816\n",
      "35 1.2878479104688252\n",
      "36 1.272825502065052\n",
      "37 1.2583527623756718\n",
      "38 1.2443968038856357\n",
      "39 1.2309274562341357\n",
      "40 1.2179169840240112\n",
      "41 1.205339840098207\n",
      "42 1.1931724486696498\n",
      "43 1.1813930140856437\n",
      "44 1.169981351591699\n",
      "45 1.1589187371639131\n",
      "46 1.1481877739126078\n",
      "47 1.1377722729641326\n",
      "48 1.1276571470269094\n",
      "49 1.1178283151055928\n",
      "50 1.1082726170352688\n",
      "51 1.0989777366851319\n",
      "52 1.0899321328298586\n",
      "53 1.0811249768149465\n",
      "54 1.0725460962517546\n",
      "55 1.064185924072565\n",
      "56 1.0560354523583644\n",
      "57 1.048086190422638\n",
      "58 1.0403301266969676\n",
      "59 1.0327596940180364\n",
      "60 1.0253677379627013\n",
      "61 1.0181474879190775\n",
      "62 1.011092530617478\n",
      "63 1.0041967858766327\n",
      "64 0.9974544843481052\n",
      "65 0.9908601470660372\n",
      "66 0.9844085666305677\n",
      "67 0.978094789871886\n",
      "68 0.9719141018583609\n",
      "69 0.9658620111263956\n",
      "70 0.9599342360227564\n",
      "71 0.9541266920609653\n",
      "72 0.9484354802036041\n",
      "73 0.9428568759910266\n",
      "74 0.9373873194448469\n",
      "75 0.9320234056815998\n",
      "76 0.9267618761779414\n",
      "77 0.9215996106345636\n",
      "78 0.9165336193907899\n",
      "79 0.911561036346153\n",
      "80 0.906679112349392\n",
      "81 0.901885209018726\n",
      "82 0.8971767929606131\n",
      "83 0.8925514303567665\n",
      "84 0.8880067818922637\n",
      "85 0.8835405979994551\n",
      "86 0.8791507143947987\n",
      "87 0.8748350478875753\n",
      "88 0.8705915924411688\n",
      "89 0.8664184154690867\n",
      "90 0.862313654349569\n",
      "91 0.8582755131435812\n",
      "92 0.8543022595025609\n",
      "93 0.8503922217529386\n",
      "94 0.8465437861458847\n",
      "95 0.8427553942611996\n",
      "96 0.8390255405554045\n",
      "97 0.8353527700446522\n",
      "98 0.8317356761138525\n",
      "99 0.8281728984439409\n",
      "100 0.8246631210499454\n",
      "101 0.8212050704227833\n",
      "102 0.8177975137685157\n",
      "103 0.8144392573389946\n",
      "104 0.8111291448482566\n",
      "105 0.8078660559695893\n",
      "106 0.804648904908349\n",
      "107 0.8014766390459777\n",
      "108 0.7983482376510425\n",
      "109 0.7952627106532855\n",
      "110 0.792219097477078\n",
      "111 0.7892164659306972\n",
      "112 0.7862539111482703\n",
      "113 0.7833305545813918\n",
      "114 0.7804455430374805\n",
      "115 0.7775980477622986\n",
      "116 0.7747872635641443\n",
      "117 0.7720124079773285\n",
      "118 0.7692727204628579\n",
      "119 0.7665674616441722\n",
      "120 0.763895912576134\n",
      "121 0.7612573740453644\n",
      "122 0.7586511659003432\n",
      "123 0.7560766264096257\n",
      "124 0.7535331116467652\n",
      "125 0.7510199949004496\n",
      "126 0.74853666610873\n",
      "127 0.7460825313158995\n",
      "128 0.743657012151094\n",
      "129 0.7412595453273414\n",
      "130 0.7388895821602645\n",
      "131 0.7365465881052459\n",
      "132 0.7342300423124095\n",
      "133 0.731939437198368\n",
      "134 0.7296742780341191\n",
      "135 0.7274340825482022\n",
      "136 0.7252183805445328\n",
      "137 0.723026713534195\n",
      "138 0.7208586343805548\n",
      "139 0.7187137069571725\n",
      "140 0.7165915058178843\n",
      "141 0.7144916158785812\n",
      "142 0.712413632110184\n",
      "143 0.7103571592422794\n",
      "144 0.708321811477098\n",
      "145 0.7063072122132807\n",
      "146 0.7043129937790815\n",
      "147 0.7023387971747038\n",
      "148 0.7003842718232611\n",
      "149 0.6984490753301155\n",
      "150 0.6965328732503113\n",
      "151 0.6946353388636136\n",
      "152 0.6927561529570613\n",
      "153 0.6908950036146088\n",
      "154 0.6890515860136588\n",
      "155 0.6872256022281902\n",
      "156 0.6854167610382657\n",
      "157 0.6836247777456287\n",
      "158 0.6818493739952565\n",
      "159 0.6800902776025401\n",
      "160 0.6783472223859963\n",
      "161 0.6766199480052083\n",
      "162 0.6749081998039085\n",
      "163 0.6732117286579257\n",
      "164 0.6715302908278981\n",
      "165 0.6698636478165432\n",
      "166 0.6682115662303167\n",
      "167 0.6665738176453572\n",
      "168 0.6649501784775138\n",
      "169 0.6633404298563322\n",
      "170 0.6617443575028952\n",
      "171 0.6601617516113144\n",
      "172 0.6585924067338168\n",
      "173 0.6570361216692986\n",
      "174 0.6554926993551528\n",
      "175 0.6539619467623501\n",
      "176 0.6524436747936431\n",
      "177 0.6509376981847349\n",
      "178 0.6494438354083948\n",
      "179 0.6479619085813324\n",
      "180 0.6464917433738498\n",
      "181 0.6450331689220447\n",
      "182 0.6435860177426498\n",
      "183 0.6421501256502152\n",
      "184 0.6407253316767518\n",
      "185 0.6393114779936584\n",
      "186 0.6379084098358342\n",
      "187 0.6365159754279905\n",
      "188 0.6351340259130266\n",
      "189 0.6337624152824125\n",
      "190 0.6324010003085512\n",
      "191 0.6310496404789959\n",
      "192 0.6297081979325517\n",
      "193 0.6283765373970799\n",
      "194 0.6270545261290789\n",
      "195 0.6257420338549036\n",
      "196 0.6244389327135953\n",
      "197 0.6231450972012855\n",
      "198 0.6218604041170931\n",
      "199 0.6205847325105187\n",
      "200 0.6193179636302157\n",
      "accuracy: 91.86999999999999\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "x0_train = np.ones((10000,1),dtype='float')\n",
    "x0_test = np.ones((5000,1),dtype='float')\n",
    "x_train, x_test = np.concatenate((x0_train,x_train),axis=1), np.concatenate((x0_test,x_test),axis=1)\n",
    "x_train_mean, x_test_mean = np.mean(x_train,axis=1), np.mean(x_test,axis=1)\n",
    "print(f'x_train: {x_train.shape}, x_train_mean: {x_train_mean.shape}')\n",
    "\n",
    "X_train, X_test = x_train - np.expand_dims(x_train_mean,axis=1), x_test - np.expand_dims(x_test_mean,axis=1)\n",
    "\n",
    "def sigmoid(z):\n",
    "    g = 1/(1+np.exp(-z))\n",
    "    return g\n",
    "\n",
    "def relu(z):\n",
    "    a, b = np.shape(z)\n",
    "    for i in range(a):\n",
    "        for j in range(b):\n",
    "            if z[i,j] < 0:\n",
    "                z[i,j] = 0\n",
    "    return z\n",
    "\n",
    "def relu_grad(z):\n",
    "    a, b = np.shape(z)\n",
    "    for i in range(a):\n",
    "        for j in range(b):\n",
    "            if z[i,j] >= 0:\n",
    "                z[i,j] = 1\n",
    "            else:\n",
    "                z[i,j] = 0\n",
    "    return z\n",
    "\n",
    "_, m = np.shape(x_train.T)\n",
    "def forward_n_backward(w1,w2,w3,x,y,alpha,lamda): # w1 - 1000 X 785, w2 - 100 X 1001, w3 - 10 X 101\n",
    "    _, m = np.shape(x) # m - no. of examples\n",
    "    b = np.ones((1,m),dtype='float') # 1 X m\n",
    "    \n",
    "    #x = np.concatenate((b,x),axis=0) # 785 X m\n",
    "    a1 = np.tanh(np.dot(w1,x)) # 1000 X m\n",
    "    a_1 = np.concatenate((b,a1),axis = 0) # 1001 X m\n",
    "    a2 = np.tanh(np.dot(w2,a_1)) # 100 X m\n",
    "    a_2 = np.concatenate((b,a2), axis=0) # 101 X m\n",
    "    h_x = sigmoid(np.dot(w3,a_2)) # 10 X m, sigmoid\n",
    "    #J = (1/m)*sum(sum(np.square(y-h_x)))\n",
    "    J = -(1/m)*sum(sum( y * np.log(abs(h_x)) + (1-y) * np.log(abs(1-h_x)) )) #+ (lamda/(2*m))*( sum(sum(np.square(w1[:,1:]))) + sum(sum(w2[:,1:])) )\n",
    "    \n",
    "    delta_net3 = (h_x - y) # 10 X m, h_x * (1 - h_x) *\n",
    "    delta_net2 = (1 - (a_2)**2) * np.dot(w3.T,delta_net3) # 101 X m, (1 - np.square(a_2)), a_2 * (1 - a_2)\n",
    "    delta_net1 = (1 - (a_1)**2) * np.dot(w2.T,delta_net2[1:,:]) # 1001 X m, (1 - np.square(a_1)), a_1 * (1 - a_1)\n",
    "    \n",
    "    #w_3, w_2, w_1 = np.concatenate((np.zeros((np.shape(w3)[0],1), dtype='float'), w3[:,1:]), axis = 1), np.concatenate((np.zeros((np.shape(w2)[0],1), dtype='float'), w2[:,1:]), axis = 1), np.concatenate((np.zeros((np.shape(w1)[0],1), dtype='float'), w1[:,1:]), axis = 1)\n",
    "    delta_w3 = np.dot(delta_net3,a_2.T)# + (lamda/m) * w_3 # 10 X 101\n",
    "    delta_w2 = np.dot(delta_net2[1:,:],a_1.T)# + (lamda/m) * w_2 # 100 X 1001\n",
    "    delta_w1 = np.dot(delta_net1[1:,:],x.T)# + (lamda/m) * w_1 # 1000 X 785\n",
    "    \n",
    "    W3 = w3 - alpha * delta_w3 # 10 X 101\n",
    "    W2 = w2 - alpha * delta_w2 # 100 X 1001\n",
    "    W1 = w1 - alpha * delta_w1 # 1000 X 785\n",
    "    \n",
    "    return J, W1, W2, W3, h_x\n",
    "\n",
    "np.random.seed(60) # 60\n",
    "\n",
    "epsilon_init1=np.sqrt(6)/np.sqrt(784+1000)\n",
    "epsilon_init2=np.sqrt(6)/np.sqrt(1000+100) \n",
    "epsilon_init3=np.sqrt(6)/np.sqrt(100+10)    \n",
    "    \n",
    "w1 = (np.random.rand(1000,1+784)*2*epsilon_init1)-epsilon_init1    \n",
    "w2 = (np.random.rand(100,1+1000)*2*epsilon_init2)-epsilon_init2\n",
    "w3 = (np.random.rand(10,1+100)*2*epsilon_init3)-epsilon_init3    \n",
    "\n",
    "J_prev = 0\n",
    "for i in range(200):\n",
    "    J , w1, w2, w3, h_x = forward_n_backward(w1, w2, w3, x_train.T, Y_train.T, 0.00001, 0 )\n",
    "    print(i+1,J)\n",
    "    if i==0:\n",
    "        J_prev = J\n",
    "    else:\n",
    "        if J > J_prev:\n",
    "            break\n",
    "        else:\n",
    "            J_prev = J\n",
    "W1, W2, W3 = w1, w2, w3 \n",
    "\n",
    "h = np.reshape(np.amax(h_x,axis=0),(1,m))\n",
    "H = h\n",
    "for i in range(9):\n",
    "    H = np.concatenate((H,h) , axis = 0)\n",
    "\n",
    "g = np.zeros(np.shape(H),dtype='int')\n",
    "for j in range(np.shape(H)[1]):\n",
    "    for i in range(np.shape(H)[0]):\n",
    "        if H[i,j] == h_x[i,j]:\n",
    "            g[i,j]=1\n",
    "\n",
    "count = 0\n",
    "y =Y_train.T\n",
    "for i in range(m):\n",
    "    if list(g[:,i]) == list(y[:,i]):\n",
    "        count = count + 1\n",
    "print('accuracy:',count/m*100) # 91.87%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f7ea67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 92.38\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "def forward(w1,w2,w3,x,y):\n",
    "    _, m = np.shape(x) # m - no. of examples\n",
    "    b = np.ones((1,m),dtype='float') # 1 X m\n",
    "    #x = np.concatenate((b,x),axis=0) # 785 X m\n",
    "    a1 = np.tanh(np.dot(w1,x)) # 1000 X m\n",
    "    a_1 = np.concatenate((b,a1),axis = 0) # 1001 X m\n",
    "    a2 = np.tanh(np.dot(w2,a_1)) # 100 X m\n",
    "    a_2 = np.concatenate((b,a2), axis=0) # 101 X m\n",
    "    h_x = sigmoid(np.dot(w3,a_2)) # 10 X m, sigmoid\n",
    "    J = (1/m)*sum(sum(np.square(y-h_x)))\n",
    "    return J, h_x\n",
    "\n",
    "J, htest_x = forward(W1, W2, W3, x_test.T, Y_test.T)    \n",
    "\n",
    "_, n = np.shape(x_test.T)\n",
    "\n",
    "h = np.reshape(np.amax(htest_x,axis=0),(1,n))\n",
    "H = h\n",
    "for i in range(9):\n",
    "    H = np.concatenate((H,h) , axis = 0)\n",
    "\n",
    "G = np.zeros(np.shape(H),dtype='int')\n",
    "for j in range(np.shape(H)[1]):\n",
    "    for i in range(np.shape(H)[0]):\n",
    "        if H[i,j] == htest_x[i,j]:\n",
    "            G[i,j]=1\n",
    "count = 0\n",
    "ytest =Y_test.T\n",
    "for i in range(n):\n",
    "    if list(G[:,i]) == list(ytest[:,i]):\n",
    "        count = count + 1\n",
    "print('accuracy:',count/n*100) # 92.38%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b0978a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 7.565770280654747\n",
      "2 3.4717308368225246\n",
      "3 3.012422200047574\n",
      "4 2.784858795111463\n",
      "5 2.6431699836113456\n",
      "6 2.5259923649169447\n",
      "7 2.4241395854939065\n",
      "8 2.334243417482547\n",
      "9 2.2540207538967687\n",
      "10 2.1818443899971185\n",
      "11 2.1164894302733543\n",
      "12 2.0569839136566808\n",
      "13 2.0025315832920714\n",
      "14 1.952470035013298\n",
      "15 1.9062445388223686\n",
      "16 1.8633889654112028\n",
      "17 1.823510455122112\n",
      "18 1.7862765746715639\n",
      "19 1.7514045261017512\n",
      "20 1.718652200384926\n",
      "21 1.6878108911866574\n",
      "22 1.6586994501842631\n",
      "23 1.6311596431700293\n",
      "24 1.6050524692730792\n",
      "25 1.5802552304523898\n",
      "26 1.5566591744585976\n",
      "27 1.5341675727322575\n",
      "28 1.5126941292670935\n",
      "29 1.492161644622823\n",
      "30 1.472500880579415\n",
      "31 1.4536495862075858\n",
      "32 1.4355516566965125\n",
      "33 1.4181564034413283\n",
      "34 1.4014179187375644\n",
      "35 1.385294521762082\n",
      "36 1.3697482748855885\n",
      "37 1.3547445611106885\n",
      "38 1.3402517147742348\n",
      "39 1.3262406987247133\n",
      "40 1.3126848220609086\n",
      "41 1.2995594932506305\n",
      "42 1.2868420040714716\n",
      "43 1.2745113403562833\n",
      "44 1.2625480160026838\n",
      "45 1.2509339271325475\n",
      "46 1.2396522236729726\n",
      "47 1.2286871959800432\n",
      "48 1.21802417444386\n",
      "49 1.2076494402987759\n",
      "50 1.1975501461172458\n",
      "51 1.1877142446902103\n",
      "52 1.1781304251919524\n",
      "53 1.1687880556951713\n",
      "54 1.1596771312445513\n",
      "55 1.1507882268170118\n",
      "56 1.1421124545972494\n",
      "57 1.1336414250803075\n",
      "58 1.125367211582244\n",
      "59 1.1172823177971192\n",
      "60 1.109379648086639\n",
      "61 1.1016524802279628\n",
      "62 1.0940944403795032\n",
      "63 1.0866994800523437\n",
      "64 1.0794618548992558\n",
      "65 1.072376105154355\n",
      "66 1.065437037574009\n",
      "67 1.058639708745781\n",
      "68 1.0519794096454718\n",
      "69 1.0454516513348278\n",
      "70 1.0390521517028732\n",
      "71 1.0327768231633672\n",
      "72 1.0266217612294175\n",
      "73 1.0205832338934022\n",
      "74 1.0146576717475644\n",
      "75 1.0088416587858753\n",
      "76 1.0031319238338499\n",
      "77 0.9975253325571087\n",
      "78 0.9920188800041598\n",
      "79 0.986609683642594\n",
      "80 0.9812949768513219\n",
      "81 0.9760721028346844\n",
      "82 0.9709385089269797\n",
      "83 0.9658917412588272\n",
      "84 0.9609294397585836\n",
      "85 0.9560493334647608\n",
      "86 0.9512492361268616\n",
      "87 0.9465270420741388\n",
      "88 0.9418807223331709\n",
      "89 0.9373083209767784\n",
      "90 0.9328079516881054\n",
      "91 0.9283777945250518\n",
      "92 0.9240160928711151\n",
      "93 0.9197211505601401\n",
      "94 0.9154913291630636\n",
      "95 0.9113250454259876\n",
      "96 0.9072207688493978\n",
      "97 0.903177019399383\n",
      "98 0.8991923653422395\n",
      "99 0.8952654211944676\n",
      "100 0.8913948457809452\n",
      "101 0.8875793403943356\n",
      "102 0.8838176470495293\n",
      "103 0.8801085468271332\n",
      "104 0.8764508583007419\n",
      "105 0.8728434360427804\n",
      "106 0.8692851692043148\n",
      "107 0.8657749801644358\n",
      "108 0.8623118232451733\n",
      "109 0.8588946834880741\n",
      "110 0.8555225754890398\n",
      "111 0.8521945422879915\n",
      "112 0.8489096543103791\n",
      "113 0.8456670083576231\n",
      "114 0.8424657266437371\n",
      "115 0.8393049558757678\n",
      "116 0.8361838663754823\n",
      "117 0.8331016512402828\n",
      "118 0.8300575255411407\n",
      "119 0.8270507255556278\n",
      "120 0.824080508034313\n",
      "121 0.8211461494986243\n",
      "122 0.8182469455687319\n",
      "123 0.8153822103197792\n",
      "124 0.8125512756651905\n",
      "125 0.8097534907655384\n",
      "126 0.8069882214617937\n",
      "127 0.8042548497317644\n",
      "128 0.8015527731685222\n",
      "129 0.7988814044798208\n",
      "130 0.796240171007435\n",
      "131 0.7936285142655221\n",
      "132 0.7910458894970327\n",
      "133 0.788491765247423\n",
      "134 0.7859656229547579\n",
      "135 0.7834669565554565\n",
      "136 0.7809952721050902\n",
      "137 0.7785500874133239\n",
      "138 0.7761309316925374\n",
      "139 0.7737373452194636\n",
      "140 0.7713688790091984\n",
      "141 0.7690250945011207\n",
      "142 0.766705563256149\n",
      "143 0.764409866664803\n",
      "144 0.7621375956657396\n",
      "145 0.7598883504741349\n",
      "146 0.7576617403195973\n",
      "147 0.7554573831931931\n",
      "148 0.753274905603194\n",
      "149 0.7511139423391604\n",
      "150 0.7489741362440423\n",
      "151 0.7468551379939663\n",
      "152 0.7447566058853761\n",
      "153 0.7426782056292336\n",
      "154 0.7406196101520239\n",
      "155 0.7385804994032342\n",
      "156 0.7365605601691084\n",
      "157 0.734559485892433\n",
      "158 0.7325769764980147\n",
      "159 0.7306127382237848\n",
      "160 0.7286664834572066\n",
      "161 0.7267379305768045\n",
      "162 0.7248268037986545\n",
      "163 0.7229328330275641\n",
      "164 0.7210557537129244\n",
      "165 0.7191953067088823\n",
      "166 0.7173512381387799\n",
      "167 0.7155232992636849\n",
      "168 0.7137112463548656\n",
      "169 0.7119148405700351\n",
      "170 0.7101338478332899\n",
      "171 0.7083680387185621\n",
      "172 0.7066171883364729\n",
      "173 0.7048810762244946\n",
      "174 0.7031594862402469\n",
      "175 0.7014522064579158\n",
      "176 0.6997590290675811\n",
      "177 0.6980797502774186\n",
      "178 0.6964141702186658\n",
      "179 0.6947620928532693\n",
      "180 0.693123325884083\n",
      "181 0.6914976806675845\n",
      "182 0.6898849721290145\n",
      "183 0.6882850186797931\n",
      "184 0.6866976421372823\n",
      "185 0.6851226676466499\n",
      "186 0.683559923604906\n",
      "187 0.6820092415869549\n",
      "188 0.6804704562736403\n",
      "189 0.6789434053817233\n",
      "190 0.6774279295957008\n",
      "191 0.6759238725014343\n",
      "192 0.6744310805215333\n",
      "193 0.6729494028524102\n",
      "194 0.6714786914030081\n",
      "195 0.670018800735097\n",
      "196 0.6685695880051182\n",
      "197 0.6671309129075128\n",
      "198 0.6657026376195495\n",
      "199 0.6642846267474893\n",
      "200 0.662876747274191\n",
      "1 7.565451493239655\n",
      "2 3.4772804835591\n",
      "3 3.0236892533830573\n",
      "4 2.799381972791141\n",
      "5 2.658869321967684\n",
      "6 2.5422580373278723\n",
      "7 2.4406513542484833\n",
      "8 2.3507865307031213\n",
      "9 2.2704393469040465\n",
      "10 2.1980352419818865\n",
      "11 2.132394339133745\n",
      "12 2.072577727231122\n",
      "13 2.0178104486574386\n",
      "14 1.967442502624218\n",
      "15 1.920925907314852\n",
      "16 1.877798132383589\n",
      "17 1.837668298184239\n",
      "18 1.8002050784702637\n",
      "19 1.7651261816337378\n",
      "20 1.732189466204167\n",
      "21 1.7011856735457678\n",
      "22 1.671932635745436\n",
      "23 1.6442707319881438\n",
      "24 1.618059337466839\n",
      "25 1.5931740251976225\n",
      "26 1.569504322482492\n",
      "27 1.546951872315764\n",
      "28 1.5254288940103136\n",
      "29 1.504856871567245\n",
      "30 1.4851654222553783\n",
      "31 1.4662913133045785\n",
      "32 1.4481776040121872\n",
      "33 1.4307728961194288\n",
      "34 1.41403067864249\n",
      "35 1.3979087554716598\n",
      "36 1.3823687455672666\n",
      "37 1.3673756467836364\n",
      "38 1.3528974553793314\n",
      "39 1.3389048341801517\n",
      "40 1.3253708231708612\n",
      "41 1.3122705870151548\n",
      "42 1.2995811946472187\n",
      "43 1.2872814266552244\n",
      "44 1.2753516066937713\n",
      "45 1.2637734536300662\n",
      "46 1.252529951550787\n",
      "47 1.2416052351395053\n",
      "48 1.2309844882787013\n",
      "49 1.220653854038091\n",
      "50 1.2106003544827866\n",
      "51 1.2008118189721488\n",
      "52 1.1912768198244534\n",
      "53 1.181984614397054\n",
      "54 1.1729250927786679\n",
      "55 1.1640887304130827\n",
      "56 1.1554665450759347\n",
      "57 1.1470500577107954\n",
      "58 1.1388312567005108\n",
      "59 1.1308025652078808\n",
      "60 1.122956811268016\n",
      "61 1.11528720035467\n",
      "62 1.107787290177169\n",
      "63 1.1004509674930434\n",
      "64 1.0932724267461964\n",
      "65 1.0862461503616088\n",
      "66 1.0793668905459786\n",
      "67 1.072629652459753\n",
      "68 1.066029678639933\n",
      "69 1.0595624345656012\n",
      "70 1.0532235952688578\n",
      "71 1.0470090329036932\n",
      "72 1.0409148051935952\n",
      "73 1.0349371446867177\n",
      "74 1.0290724487536826\n",
      "75 1.0233172702696136\n",
      "76 1.017668308926855\n",
      "77 1.0121224031300535\n",
      "78 1.006676522429176\n",
      "79 1.0013277604501125\n",
      "80 0.996073328285764\n",
      "81 0.9909105483137676\n",
      "82 0.9858368484095676\n",
      "83 0.9808497565262317\n",
      "84 0.9759468956146282\n",
      "85 0.9711259788595784\n",
      "86 0.9663848052095666\n",
      "87 0.9617212551792886\n",
      "88 0.9571332869058504\n",
      "89 0.952618932440943\n",
      "90 0.9481762942625671\n",
      "91 0.9438035419911951\n",
      "92 0.939498909296334\n",
      "93 0.9352606909805236\n",
      "94 0.9310872402286722\n",
      "95 0.9269769660118159\n",
      "96 0.922928330634712\n",
      "97 0.9189398474180291\n",
      "98 0.9150100785060679\n",
      "99 0.9111376327920384\n",
      "100 0.9073211639531825\n",
      "101 0.9035593685887752\n",
      "102 0.8998509844545511\n",
      "103 0.8961947887874638\n",
      "104 0.8925895967152018\n",
      "105 0.8890342597453795\n",
      "106 0.8855276643293962\n",
      "107 0.8820687304966954\n",
      "108 0.8786564105551354\n",
      "109 0.8752896878536767\n",
      "110 0.8719675756037406\n",
      "111 0.8686891157559271\n",
      "112 0.8654533779289578\n",
      "113 0.8622594583879041\n",
      "114 0.8591064790690466\n",
      "115 0.8559935866486948\n",
      "116 0.8529199516537603\n",
      "117 0.8498847676117022\n",
      "118 0.846887250237828\n",
      "119 0.8439266366580161\n",
      "120 0.8410021846649438\n",
      "121 0.8381131720062006\n",
      "122 0.8352588957025302\n",
      "123 0.8324386713948471\n",
      "124 0.8296518327184321\n",
      "125 0.8268977307030254\n",
      "126 0.8241757331975977\n",
      "127 0.8214852243184726\n",
      "128 0.8188256039197682\n",
      "129 0.8161962870850547\n",
      "130 0.8135967036392092\n",
      "131 0.8110262976795203\n",
      "132 0.8084845271251144\n",
      "133 0.8059708632839491\n",
      "134 0.803484790436376\n",
      "135 0.80102580543471\n",
      "136 0.7985934173179338\n",
      "137 0.7961871469409568\n",
      "138 0.7938065266176467\n",
      "139 0.7914510997771834\n",
      "140 0.7891204206329873\n",
      "141 0.7868140538637624\n",
      "142 0.7845315743061241\n",
      "143 0.7822725666582568\n",
      "144 0.7800366251941332\n",
      "145 0.7778233534879428\n",
      "146 0.7756323641481225\n",
      "147 0.7734632785607758\n",
      "148 0.7713157266418857\n",
      "149 0.7691893465981735\n",
      "150 0.7670837846960518\n",
      "151 0.7649986950384265\n",
      "152 0.7629337393491012\n",
      "153 0.7608885867643007\n",
      "154 0.7588629136311775\n",
      "155 0.7568564033129691\n",
      "156 0.7548687460005433\n",
      "157 0.7528996385300514\n",
      "158 0.750948784206534\n",
      "159 0.7490158926331614\n",
      "160 0.7471006795459096\n",
      "161 0.7452028666535407\n",
      "162 0.7433221814825465\n",
      "163 0.7414583572270208\n",
      "164 0.7396111326031543\n",
      "165 0.7377802517082515\n",
      "166 0.7359654638840576\n",
      "167 0.7341665235843101\n",
      "168 0.7323831902462083\n",
      "169 0.7306152281658954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170 0.7288624063775605\n",
      "171 0.7271244985362003\n",
      "172 0.7254012828038393\n",
      "173 0.7236925417391135\n",
      "174 0.72199806219008\n",
      "175 0.7203176351901438\n",
      "176 0.7186510558570034\n",
      "177 0.7169981232945398\n",
      "178 0.7153586404974369\n",
      "179 0.7137324142586148\n",
      "180 0.7121192550792123\n",
      "181 0.7105189770811488\n",
      "182 0.7089313979221363\n",
      "183 0.7073563387130182\n",
      "184 0.7057936239374751\n",
      "185 0.7042430813738784\n",
      "186 0.7027045420193392\n",
      "187 0.7011778400158233\n",
      "188 0.6996628125782386\n",
      "189 0.6981592999245348\n",
      "190 0.6966671452076395\n",
      "191 0.695186194449223\n",
      "192 0.6937162964752603\n",
      "193 0.6922573028532717\n",
      "194 0.6908090678312383\n",
      "195 0.6893714482781499\n",
      "196 0.6879443036260394\n",
      "197 0.686527495813609\n",
      "198 0.6851208892312971\n",
      "199 0.6837243506677183\n",
      "200 0.6823377492575757\n",
      "1 7.560335397656449\n",
      "2 3.4733727836229966\n",
      "3 3.015582814154035\n",
      "4 2.7922348735475824\n",
      "5 2.6528061350848646\n",
      "6 2.536491700222022\n",
      "7 2.4349826238234327\n",
      "8 2.345203776887194\n",
      "9 2.2649816708149837\n",
      "10 2.1927357444474285\n",
      "11 2.1272674518637307\n",
      "12 2.0676237919705844\n",
      "13 2.013023285164261\n",
      "14 1.9628149381323565\n",
      "15 1.9164523744958966\n",
      "16 1.8734750239347249\n",
      "17 1.8334931292188188\n",
      "18 1.796175340480542\n",
      "19 1.761238421828282\n",
      "20 1.7284388020846921\n",
      "21 1.6975657288563173\n",
      "22 1.668435773140216\n",
      "23 1.6408884335871992\n",
      "24 1.6147826111286916\n",
      "25 1.5899937594059823\n",
      "26 1.5664115552375186\n",
      "27 1.5439379697947586\n",
      "28 1.5224856517565069\n",
      "29 1.5019765574611912\n",
      "30 1.4823407804699742\n",
      "31 1.463515545196476\n",
      "32 1.4454443377024293\n",
      "33 1.4280761525817822\n",
      "34 1.4113648389584055\n",
      "35 1.3952685316195417\n",
      "36 1.3797491555901078\n",
      "37 1.3647719942577479\n",
      "38 1.3503053126204558\n",
      "39 1.33632002843041\n",
      "40 1.3227894250012113\n",
      "41 1.3096889002706948\n",
      "42 1.2969957474017924\n",
      "43 1.284688962787416\n",
      "44 1.2727490778278112\n",
      "45 1.26115801128932\n",
      "46 1.2498989394470426\n",
      "47 1.2389561815687982\n",
      "48 1.2283150986203517\n",
      "49 1.217962003363704\n",
      "50 1.2078840802822943\n",
      "51 1.198069313999225\n",
      "52 1.1885064250582518\n",
      "53 1.1791848121125141\n",
      "54 1.1700944997152043\n",
      "55 1.1612260910318328\n",
      "56 1.1525707248978663\n",
      "57 1.1441200367319349\n",
      "58 1.1358661228855014\n",
      "59 1.1278015080680746\n",
      "60 1.1199191155351425\n",
      "61 1.1122122397653043\n",
      "62 1.1046745213863953\n",
      "63 1.0972999241377415\n",
      "64 1.0900827136794846\n",
      "65 1.0830174380798645\n",
      "66 1.0760989098288736\n",
      "67 1.0693221892418996\n",
      "68 1.0626825691304675\n",
      "69 1.0561755606289547\n",
      "70 1.0497968800769675\n",
      "71 1.0435424368663297\n",
      "72 1.0374083221704946\n",
      "73 1.0313907984815074\n",
      "74 1.025486289886927\n",
      "75 1.0196913730251425\n",
      "76 1.0140027686633653\n",
      "77 1.0084173338475462\n",
      "78 1.0029320545781517\n",
      "79 0.9975440389700314\n",
      "80 0.9922505108582129\n",
      "81 0.9870488038149611\n",
      "82 0.9819363555466546\n",
      "83 0.9769107026415539\n",
      "84 0.971969475642376\n",
      "85 0.9671103944196068\n",
      "86 0.9623312638237863\n",
      "87 0.9576299695966004\n",
      "88 0.9530044745226013\n",
      "89 0.9484528148046274\n",
      "90 0.9439730966475522\n",
      "91 0.9395634930362414\n",
      "92 0.9352222406945532\n",
      "93 0.930947637213484\n",
      "94 0.9267380383373586\n",
      "95 0.9225918553978194\n",
      "96 0.9185075528861453\n",
      "97 0.9144836461552328\n",
      "98 0.910518699243042\n",
      "99 0.9066113228100454\n",
      "100 0.9027601721836954\n",
      "101 0.8989639455033817\n",
      "102 0.8952213819599193\n",
      "103 0.89153126012385\n",
      "104 0.8878923963574223\n",
      "105 0.8843036433052751\n",
      "106 0.8807638884593044\n",
      "107 0.8772720527934472\n",
      "108 0.8738270894644183\n",
      "109 0.870427982574602\n",
      "110 0.8670737459937075\n",
      "111 0.8637634222358388\n",
      "112 0.8604960813889304\n",
      "113 0.8572708200937508\n",
      "114 0.8540867605696312\n",
      "115 0.8509430496845605\n",
      "116 0.8478388580671197\n",
      "117 0.8447733792581349\n",
      "118 0.8417458288998765\n",
      "119 0.8387554439609035\n",
      "120 0.8358014819945694\n",
      "121 0.8328832204296172\n",
      "122 0.829999955891114\n",
      "123 0.8271510035501327\n",
      "124 0.8243356965008659\n",
      "125 0.8215533851636472\n",
      "126 0.8188034367127117\n",
      "127 0.8160852345273396\n",
      "128 0.8133981776653957\n",
      "129 0.8107416803579822\n",
      "130 0.8081151715243772\n",
      "131 0.805518094306119\n",
      "132 0.8029499056194274\n",
      "133 0.8004100757250558\n",
      "134 0.7978980878147509\n",
      "135 0.7954134376135497\n",
      "136 0.7929556329972146\n",
      "137 0.7905241936240612\n",
      "138 0.7881186505805282\n",
      "139 0.7857385460399365\n",
      "140 0.7833834329337409\n",
      "141 0.7810528746348379\n",
      "142 0.7787464446522334\n",
      "143 0.7764637263368084\n",
      "144 0.774204312597444\n",
      "145 0.7719678056272465\n",
      "146 0.76975381663936\n",
      "147 0.7675619656119778\n",
      "148 0.7653918810421548\n",
      "149 0.76324319970806\n",
      "150 0.7611155664393522\n",
      "151 0.7590086338952626\n",
      "152 0.756922062350161\n",
      "153 0.7548555194862563\n",
      "154 0.7528086801931385\n",
      "155 0.7507812263738894\n",
      "156 0.7487728467576019\n",
      "157 0.7467832367178191\n",
      "158 0.7448120980969756\n",
      "159 0.7428591390363146\n",
      "160 0.740924073811299\n",
      "161 0.7390066226721539\n",
      "162 0.7371065116894223\n",
      "163 0.735223472604351\n",
      "164 0.7333572426838514\n",
      "165 0.7315075645799766\n",
      "166 0.7296741861936463\n",
      "167 0.7278568605425364\n",
      "168 0.7260553456329466\n",
      "169 0.7242694043355093\n",
      "170 0.7224988042646088\n",
      "171 0.7207433176613708\n",
      "172 0.7190027212801059\n",
      "173 0.7172767962781087\n",
      "174 0.7155653281085881\n",
      "175 0.7138681064168229\n",
      "176 0.7121849249391872\n",
      "177 0.7105155814051562\n",
      "178 0.7088598774420884\n",
      "179 0.7072176184826818\n",
      "180 0.7055886136750762\n",
      "181 0.703972675795458\n",
      "182 0.7023696211631143\n",
      "183 0.7007792695578502\n",
      "184 0.6992014441397129\n",
      "185 0.6976359713708425\n",
      "186 0.6960826809395962\n",
      "187 0.6945414056866007\n",
      "188 0.6930119815329208\n",
      "189 0.6914942474101068\n",
      "190 0.6899880451921429\n",
      "191 0.6884932196292106\n",
      "192 0.6870096182832122\n",
      "193 0.6855370914650275\n",
      "194 0.6840754921733895\n",
      "195 0.6826246760353949\n",
      "196 0.6811845012485519\n",
      "197 0.6797548285243575\n",
      "198 0.6783355210333302\n",
      "199 0.6769264443514352\n",
      "200 0.6755274664079408\n",
      "1 7.557829676323735\n",
      "2 3.472220582268441\n",
      "3 3.016081659779603\n",
      "4 2.7864369082662517\n",
      "5 2.6447372948530137\n",
      "6 2.527299803871173\n",
      "7 2.4251655449479097\n",
      "8 2.334985555696067\n",
      "9 2.254470144319691\n",
      "10 2.181997755388972\n",
      "11 2.116355767109456\n",
      "12 2.0565838509339676\n",
      "13 2.0018940435038597\n",
      "14 1.951628923938937\n",
      "15 1.9052361631622188\n",
      "16 1.8622500826893307\n",
      "17 1.82227675852099\n",
      "18 1.7849815126156525\n",
      "19 1.7500784323894905\n",
      "20 1.7173217337872926\n",
      "21 1.6864987716407351\n",
      "22 1.6574244560732825\n",
      "23 1.6299368151897238\n",
      "24 1.6038934574610144\n",
      "25 1.5791687225682736\n",
      "26 1.555651353283281\n",
      "27 1.5332425631125852\n",
      "28 1.5118544094081212\n",
      "29 1.491408407928834\n",
      "30 1.471834343240853\n",
      "31 1.4530692416498114\n",
      "32 1.4350564814173044\n",
      "33 1.4177450203331536\n",
      "34 1.4010887243581645\n",
      "35 1.3850457836970884\n",
      "36 1.3695782047002951\n",
      "37 1.35465136764031\n",
      "38 1.3402336417763536\n",
      "39 1.3262960502664731\n",
      "40 1.3128119784503498\n",
      "41 1.2997569198385963\n",
      "42 1.2871082548334996\n",
      "43 1.2748450578005033\n",
      "44 1.2629479286304996\n",
      "45 1.2513988453994294\n",
      "46 1.2401810351553733\n",
      "47 1.2292788602508407\n",
      "48 1.2186777179920907\n",
      "49 1.2083639516983828\n",
      "50 1.1983247715513685\n",
      "51 1.188548183867526\n",
      "52 1.1790229276456974\n",
      "53 1.169738417428236\n",
      "54 1.1606846916710576\n",
      "55 1.1518523659475024\n",
      "56 1.143232590417696\n",
      "57 1.1348170110820668\n",
      "58 1.1265977344083615\n",
      "59 1.1185672949791183\n",
      "60 1.1107186258536645\n",
      "61 1.1030450313774853\n",
      "62 1.095540162203976\n",
      "63 1.088197992320599\n",
      "64 1.0810127978945923\n",
      "65 1.0739791377729664\n",
      "66 1.0670918354887968\n",
      "67 1.0603459626406757\n",
      "68 1.0537368235256024\n",
      "69 1.047259940917041\n",
      "70 1.0409110428906223\n",
      "71 1.03468605060894\n",
      "72 1.0285810669855775\n",
      "73 1.0225923661555993\n",
      "74 1.0167163836868156\n",
      "75 1.0109497074717702\n",
      "76 1.0052890692461647\n",
      "77 0.9997313366840171\n",
      "78 0.9942735060243905\n",
      "79 0.9889126951884042\n",
      "80 0.9836461373488974\n",
      "81 0.9784711749181904\n",
      "82 0.9733852539224384\n",
      "83 0.9683859187336815\n",
      "84 0.963470807133016\n",
      "85 0.9586376456805786\n",
      "86 0.9538842453700849\n",
      "87 0.9492084975471898\n",
      "88 0.9446083700729582\n",
      "89 0.9400819037150409\n",
      "90 0.9356272087504168\n",
      "91 0.9312424617651334\n",
      "92 0.9269259026373651\n",
      "93 0.9226758316912826\n",
      "94 0.9184906070102111\n",
      "95 0.9143686418983593\n",
      "96 0.9103084024812658\n",
      "97 0.9063084054359796\n",
      "98 0.902367215842398\n",
      "99 0.898483445148087\n",
      "100 0.894655749239377\n",
      "101 0.8908828266119794\n",
      "102 0.8871634166350655\n",
      "103 0.8834962979029772\n",
      "104 0.8798802866692749\n",
      "105 0.8763142353581902\n",
      "106 0.8727970311488996\n",
      "107 0.8693275946283026\n",
      "108 0.8659048785083553\n",
      "109 0.8625278664042404\n",
      "110 0.8591955716699414\n",
      "111 0.8559070362879352\n",
      "112 0.8526613298100727\n",
      "113 0.8494575483467391\n",
      "114 0.846294813601718\n",
      "115 0.843172271950329\n",
      "116 0.8400890935583567\n",
      "117 0.8370444715398555\n",
      "118 0.8340376211515835\n",
      "119 0.8310677790222711\n",
      "120 0.8281342024148775\n",
      "121 0.8252361685201971\n",
      "122 0.8223729737801795\n",
      "123 0.8195439332395165\n",
      "124 0.8167483799240525\n",
      "125 0.8139856642447091\n",
      "126 0.8112551534256909\n",
      "127 0.8085562309557717\n",
      "128 0.805888296061545\n",
      "129 0.8032507632016438\n",
      "130 0.8006430615808083\n",
      "131 0.7980646346830498\n",
      "132 0.7955149398228715\n",
      "133 0.7929934477137509\n",
      "134 0.7904996420531436\n",
      "135 0.7880330191231538\n",
      "136 0.7855930874062946\n",
      "137 0.7831793672154947\n",
      "138 0.7807913903379026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139 0.7784286996917057\n",
      "140 0.7760908489955022\n",
      "141 0.7737774024496636\n",
      "142 0.7714879344291001\n",
      "143 0.769222029187034\n",
      "144 0.766979280569242\n",
      "145 0.7647592917383637\n",
      "146 0.7625616749078211\n",
      "147 0.7603860510849721\n",
      "148 0.7582320498230984\n",
      "149 0.75609930898189\n",
      "150 0.7539874744960475\n",
      "151 0.7518962001517044\n",
      "152 0.749825147370288\n",
      "153 0.7477739849996595\n",
      "154 0.745742389112064\n",
      "155 0.7437300428087742\n",
      "156 0.7417366360310738\n",
      "157 0.73976186537741\n",
      "158 0.7378054339263643\n",
      "159 0.7358670510653383\n",
      "160 0.7339464323246848\n",
      "161 0.7320432992170609\n",
      "162 0.7301573790818293\n",
      "163 0.7282884049343092\n",
      "164 0.7264361153197535\n",
      "165 0.7246002541717345\n",
      "166 0.7227805706749663\n",
      "167 0.7209768191322681\n",
      "168 0.719188758835529\n",
      "169 0.7174161539406149\n",
      "170 0.7156587733459938\n",
      "171 0.713916390574973\n",
      "172 0.7121887836614457\n",
      "173 0.7104757350389843\n",
      "174 0.7087770314331859\n",
      "175 0.7070924637571679\n",
      "176 0.7054218270100991\n",
      "177 0.7037649201786073\n",
      "178 0.7021215461410936\n",
      "179 0.7004915115747186\n",
      "180 0.6988746268650334\n",
      "181 0.6972707060182236\n",
      "182 0.6956795665757176\n",
      "183 0.6941010295312946\n",
      "184 0.6925349192504092\n",
      "185 0.6909810633918183\n",
      "186 0.6894392928313261\n",
      "187 0.6879094415876249\n",
      "188 0.6863913467501981\n",
      "189 0.6848848484091583\n",
      "190 0.6833897895869404\n",
      "191 0.6819060161719228\n",
      "192 0.6804333768537686\n",
      "193 0.6789717230605118\n",
      "194 0.6775209088972991\n",
      "195 0.6760807910867667\n",
      "196 0.6746512289110153\n",
      "197 0.6732320841550392\n",
      "198 0.6718232210516873\n",
      "199 0.6704245062280546\n",
      "200 0.6690358086532159\n",
      "1 7.544887341136714\n",
      "2 3.447591642203174\n",
      "3 2.998981755021814\n",
      "4 2.773705583788897\n",
      "5 2.6301593867740363\n",
      "6 2.510831906581174\n",
      "7 2.407310754359387\n",
      "8 2.316359185171528\n",
      "9 2.235515552698447\n",
      "10 2.16298177663109\n",
      "11 2.097425331953933\n",
      "12 2.0378109881635385\n",
      "13 1.9833060373621694\n",
      "14 1.9332281576661456\n",
      "15 1.8870126686107358\n",
      "16 1.8441889203152844\n",
      "17 1.8043619989506854\n",
      "18 1.7671981905984224\n",
      "19 1.7324133850063115\n",
      "20 1.6997638510926818\n",
      "21 1.6690389398232566\n",
      "22 1.6400553407776681\n",
      "23 1.612652569974313\n",
      "24 1.5866894119726713\n",
      "25 1.5620410863201035\n",
      "26 1.538596956331133\n",
      "27 1.516258643139075\n",
      "28 1.494938446160152\n",
      "29 1.4745580007301997\n",
      "30 1.4550471248911288\n",
      "31 1.4363428215593208\n",
      "32 1.4183884114599308\n",
      "33 1.401132777969291\n",
      "34 1.3845297086841604\n",
      "35 1.3685373210135454\n",
      "36 1.3531175609033834\n",
      "37 1.338235765248535\n",
      "38 1.3238602797678236\n",
      "39 1.3099621251785911\n",
      "40 1.2965147054357646\n",
      "41 1.2834935526080007\n",
      "42 1.2708761036605893\n",
      "43 1.2586415050140527\n",
      "44 1.2467704412618552\n",
      "45 1.2352449848758544\n",
      "46 1.224048464117298\n",
      "47 1.2131653467154457\n",
      "48 1.2025811371837647\n",
      "49 1.1922822859207411\n",
      "50 1.1822561084913146\n",
      "51 1.1724907137086538\n",
      "52 1.162974939334129\n",
      "53 1.1536982943883078\n",
      "54 1.1446509072170659\n",
      "55 1.1358234785872858\n",
      "56 1.127207239197017\n",
      "57 1.118793911077866\n",
      "58 1.1105756724446503\n",
      "59 1.1025451256119942\n",
      "60 1.094695267650326\n",
      "61 1.0870194634980992\n",
      "62 1.0795114212835104\n",
      "63 1.0721651696394987\n",
      "64 1.0649750368216024\n",
      "65 1.0579356314598352\n",
      "66 1.051041824794613\n",
      "67 1.044288734262534\n",
      "68 1.037671708312119\n",
      "69 1.0311863123416845\n",
      "70 1.0248283156624378\n",
      "71 1.0185936793994574\n",
      "72 1.0124785452518466\n",
      "73 1.0064792250408088\n",
      "74 1.0005921909814366\n",
      "75 0.9948140666199153\n",
      "76 0.9891416183834477\n",
      "77 0.9835717476949568\n",
      "78 0.9781014836092156\n",
      "79 0.9727279759307125\n",
      "80 0.9674484887773298\n",
      "81 0.962260394556914\n",
      "82 0.9571611683266631\n",
      "83 0.952148382507848\n",
      "84 0.9472197019305677\n",
      "85 0.9423728791854518\n",
      "86 0.937605750260764\n",
      "87 0.9329162304453943\n",
      "88 0.9283023104794448\n",
      "89 0.9237620529356387\n",
      "90 0.9192935888158448\n",
      "91 0.9148951143484881\n",
      "92 0.9105648879731935\n",
      "93 0.9063012275003226\n",
      "94 0.9021025074337904\n",
      "95 0.8979671564463562\n",
      "96 0.8938936549973977\n",
      "97 0.8898805330836717\n",
      "98 0.885926368114633\n",
      "99 0.8820297829039241\n",
      "100 0.878189443769621\n",
      "101 0.8744040587362654\n",
      "102 0.8706723758320217\n",
      "103 0.8669931814749174\n",
      "104 0.8633652989425833\n",
      "105 0.8597875869200506\n",
      "106 0.8562589381209037\n",
      "107 0.8527782779770688\n",
      "108 0.8493445633931028\n",
      "109 0.845956781561001\n",
      "110 0.84261394883183\n",
      "111 0.8393151096408517\n",
      "112 0.8360593354829337\n",
      "113 0.8328457239352622\n",
      "114 0.8296733977246781\n",
      "115 0.8265415038370629\n",
      "116 0.8234492126663655\n",
      "117 0.8203957172011094\n",
      "118 0.8173802322462859\n",
      "119 0.814401993678715\n",
      "120 0.8114602577340638\n",
      "121 0.8085543003239005\n",
      "122 0.8056834163811228\n",
      "123 0.802846919232398\n",
      "124 0.8000441399961443\n",
      "125 0.7972744270048621\n",
      "126 0.794537145250506\n",
      "127 0.7918316758518766\n",
      "128 0.7891574155428465\n",
      "129 0.7865137761805452\n",
      "130 0.7839001842724364\n",
      "131 0.7813160805215177\n",
      "132 0.7787609193887031\n",
      "133 0.7762341686716964\n",
      "134 0.7737353090994943\n",
      "135 0.7712638339419239\n",
      "136 0.7688192486335069\n",
      "137 0.7664010704109784\n",
      "138 0.7640088279639488\n",
      "139 0.7616420610980359\n",
      "140 0.7593003204100383\n",
      "141 0.7569831669745691\n",
      "142 0.7546901720416794\n",
      "143 0.7524209167450197\n",
      "144 0.7501749918201323\n",
      "145 0.7479519973323642\n",
      "146 0.7457515424141358\n",
      "147 0.7435732450110732\n",
      "148 0.7414167316367166\n",
      "149 0.7392816371354274\n",
      "150 0.7371676044531799\n",
      "151 0.7350742844159504\n",
      "152 0.7330013355153424\n",
      "153 0.7309484237012256\n",
      "154 0.7289152221811229\n",
      "155 0.7269014112260416\n",
      "156 0.7249066779824863\n",
      "157 0.7229307162905494\n",
      "158 0.7209732265076735\n",
      "159 0.7190339153379854\n",
      "160 0.7171124956669961\n",
      "161 0.7152086864014231\n",
      "162 0.7133222123139215\n",
      "163 0.7114528038926629\n",
      "164 0.7096001971954853\n",
      "165 0.7077641337084345\n",
      "166 0.7059443602086466\n",
      "167 0.7041406286313044\n",
      "168 0.702352695940601\n",
      "169 0.7005803240045173\n",
      "170 0.6988232794733231\n",
      "171 0.6970813336616489\n",
      "172 0.6953542624339878\n",
      "173 0.6936418460935693\n",
      "174 0.6919438692744055\n",
      "175 0.6902601208365025\n",
      "176 0.6885903937640117\n",
      "177 0.6869344850663561\n",
      "178 0.6852921956821005\n",
      "179 0.6836633303855738\n",
      "180 0.6820476976961107\n",
      "181 0.6804451097898172\n",
      "182 0.6788553824138027\n",
      "183 0.677278334802806\n",
      "184 0.6757137895980719\n",
      "185 0.6741615727685103\n",
      "186 0.6726215135339594\n",
      "187 0.6710934442905744\n",
      "188 0.6695772005382228\n",
      "189 0.6680726208098189\n",
      "190 0.6665795466025743\n",
      "191 0.6650978223110857\n",
      "192 0.663627295162189\n",
      "193 0.6621678151515467\n",
      "194 0.6607192349818953\n",
      "195 0.6592814100029407\n",
      "196 0.6578541981527972\n",
      "197 0.6564374599009546\n",
      "198 0.6550310581927425\n",
      "199 0.653634858395204\n",
      "200 0.652248728244385\n",
      "90.25000000000001\n"
     ]
    }
   ],
   "source": [
    "# five fold cross validation\n",
    "x, y = x_train.T, Y_train.T\n",
    "acc = []\n",
    "for i in range(5):\n",
    "    Xtest, Ytest = x[:,2000*i:2000*i+2000], y[:,2000*i:2000+2000*i]\n",
    "    if i==0:\n",
    "        Xtrain, Ytrain = x[:,2000:10000], y[:,2000:10000]\n",
    "    elif i==1:\n",
    "        Xtrain, Ytrain = np.concatenate((x[:,0:2000],x[:,4000:10000]),axis=1), np.concatenate((y[:,0:2000],y[:,4000:10000]),axis=1)\n",
    "    elif i==2:\n",
    "        Xtrain, Ytrain = np.concatenate((x[:,0:4000],x[:,6000:10000]),axis=1), np.concatenate((y[:,0:4000],y[:,6000:10000]),axis=1)\n",
    "    elif i==3:\n",
    "        Xtrain, Ytrain = np.concatenate((x[:,0:6000],x[:,8000:10000]),axis=1), np.concatenate((y[:,0:6000],y[:,8000:10000]),axis=1)\n",
    "    else:\n",
    "        Xtrain, Ytrain = x[:,0:8000], y[:,0:8000]\n",
    "    \n",
    "    np.random.seed(60) # 60\n",
    "\n",
    "    epsilon_init1=np.sqrt(6)/np.sqrt(784+1000)\n",
    "    epsilon_init2=np.sqrt(6)/np.sqrt(1000+100) \n",
    "    epsilon_init3=np.sqrt(6)/np.sqrt(100+10)    \n",
    "        \n",
    "    w1 = (np.random.rand(1000,1+784)*2*epsilon_init1)-epsilon_init1    \n",
    "    w2 = (np.random.rand(100,1+1000)*2*epsilon_init2)-epsilon_init2\n",
    "    w3 = (np.random.rand(10,1+100)*2*epsilon_init3)-epsilon_init3 \n",
    "    \n",
    "    J_prev = 0\n",
    "    for j in range(200):\n",
    "        J , w1, w2, w3, h_x = forward_n_backward(w1, w2, w3, Xtrain, Ytrain, 0.00001, 0 )\n",
    "        print(j+1,J)\n",
    "        if j==0:\n",
    "            J_prev = J\n",
    "        else:\n",
    "            if J > J_prev:\n",
    "                break\n",
    "            else:\n",
    "                J_prev = J\n",
    "    W_1, W_2, W_3 = w1, w2, w3 \n",
    "\n",
    "    J, h_test_x = forward(W_1, W_2, W_3, Xtest, Ytest)  \n",
    "\n",
    "    _, N = np.shape(Xtest)\n",
    "\n",
    "    h = np.reshape(np.amax(h_test_x,axis=0),(1,N))\n",
    "    H = h\n",
    "    for j in range(9):\n",
    "        H = np.concatenate((H,h) , axis = 0)\n",
    "    \n",
    "    K = np.zeros(np.shape(H),dtype='int')\n",
    "    for j in range(np.shape(H)[1]):\n",
    "        for i in range(np.shape(H)[0]):\n",
    "            if H[i,j] == h_test_x[i,j]:\n",
    "                K[i,j]=1\n",
    "    count = 0\n",
    "    #ytest =Y_test.T\n",
    "    for j in range(N):\n",
    "        if list(K[:,j]) == list(Ytest[:,j]):\n",
    "            count = count + 1\n",
    "    accuracy = count/N*100\n",
    "    acc.append(accuracy)\n",
    "\n",
    "print(np.mean(acc))# 90.25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3197b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[472   0   1   2   1   1   4   2   0   0]\n",
      " [  0 545   5   2   0   4   0   1   4   0]\n",
      " [  7   8 429   5   6   2   5   5  14   3]\n",
      " [  1   4  16 439   0  17   1   7   3   6]\n",
      " [  0   4   7   0 506   0   7   0   1  16]\n",
      " [ 10   2   3  19   4 375  10   1   8   4]\n",
      " [  2   2   1   0   3   6 481   0   4   0]\n",
      " [  6   7   4   0  13   0   0 501   1  10]\n",
      " [  2   9   6  10   2   6   4   0 422   3]\n",
      " [  8   2   0   5  10   3   2  15   2 449]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "labels = np.array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]) \n",
    "confmatrix = confusion_matrix(np.argmax(Y_test,axis=1), np.argmax(htest_x.T,axis=1)) \n",
    "print(confmatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96443ceb",
   "metadata": {},
   "source": [
    "# Model and GD written using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb2c66ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "file_path='mnist.pkl'\n",
    "with open(file_path, 'rb') as f:\n",
    "    x = pickle.load(f, encoding='latin1')\n",
    "\n",
    "y_train=[]\n",
    "x_train=[]\n",
    "y_test=[]\n",
    "x_test=[]\n",
    "##### generating 1000 per class for training ###########\n",
    "ij=np.zeros([10,1])\n",
    "for (ii,i) in enumerate((x[0])[1]):\n",
    "    for j in range(0,10):\n",
    "        if ((i==j) and (int(ij[j,0])<1000)):\n",
    "            x_train.append(((x[0])[0])[ii])\n",
    "            y_train.append(((x[0])[1])[ii])\n",
    "            ij[j,0]+=1\n",
    "\n",
    "##### generating 500 per class for testing ###########            \n",
    "ik=np.zeros([10,1])\n",
    "for (ji,k) in enumerate((x[1])[1]):\n",
    "    for j1 in range(0,10):\n",
    "        if ((k==j1) and (int(ik[j1,0])<500)):\n",
    "            x_test.append(((x[0])[0])[ji])\n",
    "            y_test.append(((x[0])[1])[ji])\n",
    "            ik[j1,0]+=1\n",
    "            \n",
    "x_train, x_test, y_train, y_test = np.asarray(x_train), np.asarray(x_test), np.asarray(y_train), np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1b03884",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train, Y_test = np.zeros((10000,10),dtype='int'), np.zeros((5000,10),dtype='int')\n",
    "for i in range(len(y_train)):\n",
    "    a = y_train[i]\n",
    "    Y_train[i,a] = 1\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    b = y_test[i]\n",
    "    Y_test[i,b] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6bf769c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alfah\\anaconda3\\envs\\mlip\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, input_dim=784, activation='tanh'))\n",
    "model.add(Dense(100, activation='tanh'))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "\n",
    "# compile the keras model\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0925152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 2s 11ms/step - loss: 0.6493 - accuracy: 0.8185\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 0.3279 - accuracy: 0.9100\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 0.2796 - accuracy: 0.9198\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 0.2485 - accuracy: 0.9304\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2246 - accuracy: 0.9387\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 0.2032 - accuracy: 0.9443\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.1873 - accuracy: 0.9461\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1721 - accuracy: 0.9510\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 0.1579 - accuracy: 0.9568\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 0.1482 - accuracy: 0.9585\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.1289 - accuracy: 0.9680\n",
      "Accuracy: 96.80\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, Y_train, epochs=10, batch_size=100) # training accuracy : 95.69\n",
    "\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(x_test, Y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100)) # testing accuracy : 96.58  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e26c7e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model\n",
    "import h5py\n",
    "model.save('mlip_pa4_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlip",
   "language": "python",
   "name": "mlip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
